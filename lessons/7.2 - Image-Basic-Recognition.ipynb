{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image-Basic-Recognition_static"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O Sistema deve identificar as provas a serem analisadas, independente de sua posição"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [1]Desta forma haverá um delimitador na câmera, onde analizará apenas as informações contidas em seu espaço"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [2]Desta forma após identificar o padrão, irá contabilizar 3 segundos para salvar uma cópia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alinhando a prova"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Homografia Estimada : \n",
      " [[ 1.02676150e-03 -9.92268060e-01  1.30003299e+03]\n",
      " [ 9.91042877e-01 -2.20317906e-03  4.28361524e+00]\n",
      " [ 7.99113456e-06 -1.05112905e-05  1.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    " \n",
    "#função responsável por alinhar as imagens baseado no template pré-configurado\n",
    "def align_images(im1, im2):\n",
    "    MAX_FEATURES = 500\n",
    "    GOOD_MATCH_PERCENT = 0.15\n",
    "    \n",
    "    #Alterando imagens para escola cinza\n",
    "    im1Gray = cv2.cvtColor(im1, cv2.COLOR_BGR2GRAY)\n",
    "    im2Gray = cv2.cvtColor(im2, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    #Detectando características do ORB e calculando descritores.\n",
    "    orb = cv2.ORB_create(MAX_FEATURES)\n",
    "    keypoints1, descriptors1 = orb.detectAndCompute(im1Gray, None)\n",
    "    keypoints2, descriptors2 = orb.detectAndCompute(im2Gray, None)\n",
    "    \n",
    "    # Ocorrências de características\n",
    "    matcher = cv2.DescriptorMatcher_create(cv2.DESCRIPTOR_MATCHER_BRUTEFORCE_HAMMING)\n",
    "    matches = matcher.match(descriptors1, descriptors2, None)\n",
    "\n",
    "    # Ordenando melhores ocorrências\n",
    "    matches.sort(key=lambda x: x.distance, reverse=False)\n",
    "    \n",
    "    # Removendo ocorrências que não possuem melhores porcentagem de reconhecimento\n",
    "    numGoodMatches = int(len(matches) * GOOD_MATCH_PERCENT)\n",
    "    matches = matches[:numGoodMatches]\n",
    "    \n",
    "    # Draw melhores matches\n",
    "    imMatches = cv2.drawMatches(im1, keypoints1, im2, keypoints2, matches, None)\n",
    "    cv2.imshow('imMatches', imMatches)\n",
    "    cv2.waitKey(0)\n",
    "    \n",
    "    \n",
    "    # Extraindo localização de melhores correspondências\n",
    "    points1 = np.zeros((len(matches), 2), dtype=np.float32)\n",
    "    points2 = np.zeros((len(matches), 2), dtype=np.float32)\n",
    "\n",
    "    for i, match in enumerate(matches):\n",
    "        points1[i, :] = keypoints1[match.queryIdx].pt\n",
    "        points2[i, :] = keypoints2[match.trainIdx].pt\n",
    "\n",
    "    # buscando homografia\n",
    "    h, mask = cv2.findHomography(points1, points2, cv2.RANSAC)\n",
    "\n",
    "    # Usando homografia\n",
    "    height, width, channels = im2.shape\n",
    "    im1Reg = cv2.warpPerspective(im1, h, (width, height))\n",
    "\n",
    "    return im1Reg, h\n",
    "\n",
    "# Read reference image\n",
    "refFilename = \"dataset/imgs/gabarito_template_geral.png\"\n",
    "imReference = cv2.imread(refFilename, cv2.IMREAD_COLOR)\n",
    "\n",
    "# Lendo Imagem a alinhar\n",
    "imFilename = \"dataset/imgs/gabarito_template_geral_preenchido_vertical.png\"\n",
    "im = cv2.imread(imFilename, cv2.IMREAD_COLOR)\n",
    "\n",
    "# A imagem alinhada será restaurada na imReg. \n",
    "# A homografia estimada será armazenada em h.\n",
    "imReg, h = align_images(im, imReference)\n",
    "\n",
    "cv2.imshow('aligned', imReg)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "print(\"Homografia Estimada : \\n\",  h)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identificando respostas do gabarito"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: ['E', 'A'], 2: [], 3: [], 4: ['C'], 5: ['B'], 6: [], 7: [], 8: [], 9: [], 10: ['A']}\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def answer(ponto_ocupacao):\n",
    "    global width\n",
    "    ocupacao = round((ponto_ocupacao*100)/width)\n",
    "    if ocupacao < 30:\n",
    "        return 'A'\n",
    "    if ocupacao < 50:\n",
    "        return 'B'\n",
    "    if ocupacao < 70:\n",
    "        return 'C'\n",
    "    if ocupacao < 90:\n",
    "        return 'D'\n",
    "    return 'E'\n",
    "\n",
    "def coordinates_question(img):\n",
    "\n",
    "    # Criando o detector baseado na versão do CV\n",
    "    is_cv3 = cv2.__version__.startswith(\"3.\")\n",
    "    if is_cv3:\n",
    "        detector = cv2.SimpleBlobDetector_create()\n",
    "    else:\n",
    "        detector = cv2.SimpleBlobDetector()\n",
    "     \n",
    "    #Detectando corpos\n",
    "    keypoints = detector.detect(img)    \n",
    "    # Criando nova imagem com os elementos identificandos pelo detector\n",
    "    #im_with_keypoints = cv2.drawKeypoints(img, keypoints, np.array([]),(0,0,255), cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "    return keypoints\n",
    "\n",
    "def evaluate_question(image):\n",
    "    \n",
    "    #global template\n",
    "    \n",
    "    coordinates = coordinates_question(image)  \n",
    "    response = []\n",
    "    if coordinates:\n",
    "        for point in coordinates:            \n",
    "            response.append(answer(point.pt[0]))\n",
    "#     im_with_keypoints = cv2.drawKeypoints(template, coordinates, np.array([]),(0,0,255), cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "#     cv2.imshow('im_with_keypoints', im_with_keypoints)\n",
    "#     cv2.waitKey(0)    \n",
    "    return response\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    image = cv2.imread('dataset/imgs/gabarito_template_geral_preenchido.png')\n",
    "    template = cv2.imread('dataset/imgs/gabarito_template_geral_alternativas.png',0)\n",
    "\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    result = cv2.matchTemplate(gray, template, cv2.TM_CCOEFF)\n",
    "    min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(result)\n",
    "\n",
    "    height, width = template.shape[:2]\n",
    "\n",
    "    #Create Bounding Box\n",
    "    top_left = max_loc\n",
    "    bottom_right = (top_left[0] + width, top_left[1] + height)\n",
    "    #cv2.rectangle(image, top_left, bottom_right, (0,0,255), 2)\n",
    "\n",
    "    answer_values = {}\n",
    "    for i in range(0,10):\n",
    "        bottom_right = (bottom_right[0], bottom_right[1] + height)\n",
    "        top_left = (top_left[0],top_left[1]+height)\n",
    "        #cv2.rectangle(image, top_left, bottom_right, (0,0,255), 2)\n",
    "\n",
    "        cropped = image[top_left[1]:bottom_right[1],top_left[0]:bottom_right[0]]\n",
    "\n",
    "        answer_values[i+1] = evaluate_question(cropped)\n",
    "\n",
    "    print(answer_values)\n",
    "    cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
